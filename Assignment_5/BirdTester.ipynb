{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-22T16:08:55.978780Z",
     "start_time": "2024-12-22T16:08:22.341647Z"
    }
   },
   "source": [
    "import gymnasium as gym\n",
    "import flappy_bird_gymnasium\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import cv2  # For visualization\n",
    "\n",
    "class DQN(torch.nn.Module):\n",
    "    def __init__(self, input_channels=1, n_actions=2):\n",
    "        super(DQN, self).__init__()\n",
    "        self.conv_layers = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(input_channels, 32, kernel_size=8, stride=4),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.fc_layers = torch.nn.Sequential(\n",
    "            torch.nn.Linear(3136, 512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(512, n_actions)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc_layers(x)\n",
    "\n",
    "def preprocess_frame(frame):\n",
    "    \"\"\"Convert and preprocess a single frame\"\"\"\n",
    "    if frame is None:\n",
    "        raise ValueError(\"Received None instead of a frame\")\n",
    "    \n",
    "    # Convert to PIL Image and preprocess\n",
    "    image = Image.fromarray(frame)\n",
    "    gray = image.convert(\"L\")\n",
    "    resized = gray.resize((84, 84))\n",
    "    \n",
    "    # Convert to tensor and normalize\n",
    "    tensor = torch.FloatTensor(np.array(resized)) / 255.0\n",
    "    return tensor.unsqueeze(0).unsqueeze(0)  # Add batch and channel dimensions\n",
    "\n",
    "def visualize_agent(model_path, num_episodes=20):\n",
    "    \"\"\"\n",
    "    Load a trained model and visualize it playing Flappy Bird\n",
    "    \n",
    "    Args:\n",
    "        model_path (str): Path to the saved model file\n",
    "        num_episodes (int): Number of episodes to play\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Set up device\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(f\"Using device: {device}\")\n",
    "\n",
    "        # Load model\n",
    "        if not os.path.exists(model_path):\n",
    "            raise FileNotFoundError(f\"Model not found at {model_path}\")\n",
    "        \n",
    "        # Initialize model and load weights\n",
    "        model = DQN().to(device)\n",
    "        checkpoint = torch.load(model_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        model.eval()\n",
    "        \n",
    "        print(f\"Loaded model from episode {checkpoint['episode']} with avg reward: {checkpoint['reward']:.2f}\")\n",
    "        \n",
    "        # Create environment with rgb_array render mode\n",
    "        env = gym.make(\"FlappyBird-v0\", render_mode=\"rgb_array\")\n",
    "        scores = []\n",
    "        \n",
    "        # Create window for visualization\n",
    "        cv2.namedWindow('Flappy Bird', cv2.WINDOW_NORMAL)\n",
    "        cv2.resizeWindow('Flappy Bird', 400, 600)\n",
    "        \n",
    "        for episode in range(num_episodes):\n",
    "            state, _ = env.reset()\n",
    "            frame = env.render()\n",
    "            state = preprocess_frame(frame)\n",
    "            episode_reward = 0\n",
    "            done = False\n",
    "            \n",
    "            while not done:\n",
    "                # Display the frame\n",
    "                cv2.imshow('Flappy Bird', cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
    "                if cv2.waitKey(20) & 0xFF == ord('q'):  # Press 'q' to quit\n",
    "                    return\n",
    "                \n",
    "                # Get action from model\n",
    "                with torch.no_grad():\n",
    "                    state = state.to(device)\n",
    "                    q_values = model(state)\n",
    "                    action = q_values.max(1)[1].item()\n",
    "                \n",
    "                # Take action\n",
    "                next_state, reward, done, truncated, _ = env.step(action)\n",
    "                \n",
    "                # Get next state\n",
    "                frame = env.render()\n",
    "                next_state = preprocess_frame(frame)\n",
    "                \n",
    "                episode_reward += reward\n",
    "                state = next_state\n",
    "                \n",
    "            scores.append(episode_reward)\n",
    "            print(f\"Episode {episode + 1}/{num_episodes} - Score: {episode_reward:.2f}\")\n",
    "        \n",
    "        # Print statistics\n",
    "        print(\"\\nGame Statistics:\")\n",
    "        print(f\"Average Score: {np.mean(scores):.2f}\")\n",
    "        print(f\"Best Score: {max(scores):.2f}\")\n",
    "        print(f\"Worst Score: {min(scores):.2f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during visualization: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    finally:\n",
    "        env.close()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    model_path = \"downloaded_models/dqn_best.pth\"  # Change this to your model path\n",
    "    visualize_agent(model_path)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loaded model from episode 1618 with avg reward: 12.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mihai\\AppData\\Local\\Temp\\ipykernel_22828\\434644260.py:66: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1/20 - Score: 4.50\n",
      "Episode 2/20 - Score: 1.50\n",
      "Episode 3/20 - Score: -0.50\n",
      "Episode 4/20 - Score: -4.80\n",
      "Episode 5/20 - Score: 1.40\n",
      "Episode 6/20 - Score: 1.50\n",
      "Episode 7/20 - Score: 1.40\n",
      "Episode 8/20 - Score: 1.40\n",
      "Episode 9/20 - Score: 1.40\n",
      "Episode 10/20 - Score: 0.90\n",
      "Episode 11/20 - Score: 1.40\n",
      "Episode 12/20 - Score: 3.50\n",
      "Episode 13/20 - Score: -1.20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[15], line 130\u001B[0m\n\u001B[0;32m    127\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    128\u001B[0m     \u001B[38;5;66;03m# Example usage\u001B[39;00m\n\u001B[0;32m    129\u001B[0m     model_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdownloaded_models/dqn_best.pth\u001B[39m\u001B[38;5;124m\"\u001B[39m  \u001B[38;5;66;03m# Change this to your model path\u001B[39;00m\n\u001B[1;32m--> 130\u001B[0m     \u001B[43mvisualize_agent\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_path\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[15], line 90\u001B[0m, in \u001B[0;36mvisualize_agent\u001B[1;34m(model_path, num_episodes)\u001B[0m\n\u001B[0;32m     87\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m done:\n\u001B[0;32m     88\u001B[0m     \u001B[38;5;66;03m# Display the frame\u001B[39;00m\n\u001B[0;32m     89\u001B[0m     cv2\u001B[38;5;241m.\u001B[39mimshow(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFlappy Bird\u001B[39m\u001B[38;5;124m'\u001B[39m, cv2\u001B[38;5;241m.\u001B[39mcvtColor(frame, cv2\u001B[38;5;241m.\u001B[39mCOLOR_RGB2BGR))\n\u001B[1;32m---> 90\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mcv2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwaitKey\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m20\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;241m&\u001B[39m \u001B[38;5;241m0xFF\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mord\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mq\u001B[39m\u001B[38;5;124m'\u001B[39m):  \u001B[38;5;66;03m# Press 'q' to quit\u001B[39;00m\n\u001B[0;32m     91\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[0;32m     93\u001B[0m     \u001B[38;5;66;03m# Get action from model\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
